% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/MVN.R
\name{MVN}
\alias{MVN}
\title{Multivariate Newton Optimisation}
\usage{
MVN(
  f,
  inits,
  data,
  minimum,
  tol,
  maxit,
  method = "MVN",
  gradfn,
  hessfn,
  jacobfn
)
}
\arguments{
\item{f}{function to be minimised}

\item{inits}{vector of initial values to be minimised}

\item{data}{(optional) dataframe with appropriate number of columns for number of variables being optimised}

\item{minimum}{search for minimum or maximum (takes TRUE if minimum search, FALSE if maximum search)}

\item{tol}{tolerance level}

\item{maxit}{maximum number of iterations run before stopping}

\item{method}{identifier, takes "MVN" only to allow the parent function to call on it}

\item{gradfn}{(optional) gradient function of f, uses finite differencing otherwise}

\item{hessfn}{(optional) hessian function of f, uses finite differencing otherwise}

\item{jacobfn}{NULL variable, included to match parent function inputs}
}
\value{
A list containing:
\item{estimate}{Optimised estimate}
\item{feval}{Function evaluated at optimised estimate}
\item{grad}{Gradient of function at optimised estimate}
\item{tolerance}{Tolerance level reached through optimisation}
\item{conv}{Whether or not the optimisation converged. 0 - converged, 1 - did not converge, 2 - max iterations reached}
\item{niter}{Number of iterations run}
}
\description{
Performs multivariate optimisation using Newton's method
}
\note{
This function is one of 5 to be called with the parent function 'funoptim', also included in this package.
}
\examples{
f <- function(theta){
x <- theta[1]
y <- theta[2]
return((x-3)^2 + (y+2)^2)
}

MVN(f = f, inits = c(4, -1), data = NULL, minimum = TRUE, tol = 0.000001, maxit = 100, method = "MVN", gradfn = NULL, hessfn = NULL, jacobfn = NULL)
}
\references{
Swallow, B. (2025, October 29th). Multivariate Optimization (Lecture).
University of St Andrews.
\url{https://moody.st-andrews.ac.uk/moodle/pluginfile.php/2128841/mod_resource/content/2/Chpater7_12.pdf}
}
\author{
Holly Goldsmith
}
