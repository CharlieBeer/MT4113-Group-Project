% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/GN.R
\name{GN}
\alias{GN}
\title{Gauss-Newton Method}
\usage{
GN(
  f,
  inits,
  data = NULL,
  minimum = TRUE,
  tol = 1e-10,
  maxit = 1000,
  method = "GN",
  gradfn = NULL,
  hessfn = NULL,
  jacobfn = NULL
)
}
\arguments{
\item{f}{the function to be optimised - if no dataframe provided, f MUST return vector of residuals directly}

\item{inits}{a vector of initial guesses for each parameter to be optimised.}

\item{data}{(optional, if f returns residuals) dataframe containing the data}

\item{tol}{tolerance level}

\item{maxit}{maximum number of iterations run before stopping}

\item{method}{identifier, takes "GN" only to allow the parent function to call on it}

\item{gradfn}{NULL variable, included to match parent function inputs}

\item{hessfn}{NULL variable, included to match parent function inputs}

\item{jacobfn}{(optional) Jacobian function of residuals, uses numerical approximation otherwise}
}
\value{
A list containing:
\item{estimate}{Optimised estimate}
\item{feval}{Function evaluated at optimised estimate}
\item{grad}{Gradient of function at optimised estimate}
\item{tolerance}{Tolerance level reached through optimisation}
\item{conv}{Whether or not the optimisation converged. 0 - converged, 1 - failed, 2 - max iterations reached}
\item{niter}{Number of iterations ran}
}
\description{
Performs non-linear least squares optimisation using Gauss-Newton method
}
\examples{
test_f <- function(theta) {
x <- theta[1]
y <- theta[2]
return(c(x - 3, y + 2))
}
test_inits <- c(0, 0)
GN(f = test_f, inits = test_inits, data = NULL)
}
\references{
Swallow, B. (2025). Non-Linear Least Squares.
University of St Andrews.
\url{https://moody.st-andrews.ac.uk/moodle/pluginfile.php/2128840/mod_resource/content/4/_book/non-linear-least-squares.html#gauss-newton-method}
}
\author{
Ilana Goldman
}
